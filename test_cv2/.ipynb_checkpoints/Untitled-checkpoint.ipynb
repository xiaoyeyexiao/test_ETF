{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f2471-ea32-45b7-8277-460a0fbbe35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rectangles[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# 加载Dlib的人脸检测器和面部关键点检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# 读取图像并转换为灰度图像\n",
    "image = cv2.imread(\"tatata.jpg\")\n",
    "\n",
    "# 将图像缩放为原始大小的一半（你可以根据需要进行调整）\n",
    "scale_percent = 50 # 缩放比例\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "resized_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 使用人脸检测器检测图像中的人脸\n",
    "faces = detector(gray)\n",
    "print(faces)\n",
    "for face in faces:\n",
    "    # 检测人脸的面部特征点\n",
    "    landmarks = predictor(gray, face)\n",
    "    \n",
    "    # 根据面部特征点的索引获取鼻子的坐标\n",
    "    nose_tip = (landmarks.part(30).x, landmarks.part(30).y)\n",
    "    nose_left = (landmarks.part(31).x, landmarks.part(31).y)\n",
    "    nose_right = (landmarks.part(35).x, landmarks.part(35).y)\n",
    "    \n",
    "    # 调整鼻孔区域大小\n",
    "    # 增大鼻孔区域\n",
    "    nose_tip = (nose_tip[0], nose_tip[1] - 10)\n",
    "    nose_left = (nose_left[0] - 5, nose_left[1])\n",
    "    nose_right = (nose_right[0] + 5, nose_right[1])\n",
    "    # 缩小鼻孔区域\n",
    "    # nose_tip = (nose_tip[0], nose_tip[1] + 10)\n",
    "    # nose_left = (nose_left[0] + 5, nose_left[1])\n",
    "    # nose_right = (nose_right[0] - 5, nose_right[1])\n",
    "    \n",
    "    # 在图像上绘制鼻孔区域\n",
    "    cv2.circle(resized_image, nose_tip, 3, (0, 255, 0), -1)\n",
    "    cv2.circle(resized_image, nose_left, 3, (0, 255, 0), -1)\n",
    "    cv2.circle(resized_image, nose_right, 3, (0, 255, 0), -1)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow(\"Nose Region\", resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a0b90-5b12-4e4e-9563-396fb5f38cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@0.038] global persistence.cpp:512 open Can't open file: '/home/mengqingyi/anaconda3/envs/tor13/lib/python3.8/site-packages/cv2/data/haarcascade_mcs_nose.xml' in read mode\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 加载人脸和鼻子检测器\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "nose_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_mcs_nose.xml')\n",
    "\n",
    "# 加载图像\n",
    "image = cv2.imread('tatata.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 检测人脸\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# 对每个检测到的人脸进行处理\n",
    "for (x, y, w, h) in faces:\n",
    "    # 在原始图像上绘制人脸矩形框\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    # 获取人脸区域\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # 在人脸区域检测鼻子\n",
    "    noses = nose_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(10, 10))\n",
    "    \n",
    "    # 对每个检测到的鼻子进行处理\n",
    "    for (nx, ny, nw, nh) in noses:\n",
    "        # 在人脸区域绘制鼻子矩形框\n",
    "        cv2.rectangle(roi_color, (nx, ny), (nx+nw, ny+nh), (0, 255, 0), 2)\n",
    "\n",
    "# 显示带有人脸和鼻子检测结果的图像\n",
    "cv2.imshow('Face and Nose Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99130190-cd44-4c77-9166-4848c1fc04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 加载两张错位的图像\n",
    "image1 = cv2.imread(\"tt2.jpg\")\n",
    "image2 = cv2.imread(\"tt1.jpg\")\n",
    "\n",
    "# exit()\n",
    "image1 = cv2.resize(image1, (1280, 720), interpolation=cv2.INTER_LINEAR)\n",
    "# print(image1.shape)\n",
    "\n",
    "# 转换为灰度图像\n",
    "gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 初始化特征检测器\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# 在两张图像中检测特征点和描述符\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "# 初始化特征匹配器\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "\n",
    "# 对特征描述符进行匹配\n",
    "matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "# 将匹配点按照距离排序\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# 选择前几个最佳匹配点\n",
    "num_good_matches = int(len(matches) * 0.15)\n",
    "good_matches = matches[:num_good_matches]\n",
    "\n",
    "# 提取匹配点的坐标\n",
    "points1 = np.float32([keypoints1[match.queryIdx].pt for match in good_matches]).reshape(-1, 1, 2)\n",
    "points2 = np.float32([keypoints2[match.trainIdx].pt for match in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# 计算变换矩阵\n",
    "transform_matrix, _ = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "# 对图像1进行变换，使其与图像2对齐\n",
    "aligned_image1 = cv2.warpPerspective(image1, transform_matrix, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 显示对齐后的图像\n",
    "cv2.imshow(\"Aligned Image 1\", aligned_image1)\n",
    "cv2.imshow(\"Image 2\", image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3a55e-c548-4774-9284-fe3a1dbbde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 加载图像\n",
    "image = cv2.imread('tt2.jpg')\n",
    "\n",
    "# 转换为灰度图像\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 二值化处理\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# 查找轮廓\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# 绘制轮廓\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# 显示带有轮廓的图像\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ecc077-c639-438e-a2aa-507f2a4e6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图片\n",
    "image = cv2.imread('tt1.jpg')\n",
    "\n",
    "# 将图像转换为灰度\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 使用Canny边缘检测\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# 找到轮廓\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# 在原始图像上绘制轮廓\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31751d9-dd6c-4bf2-9e89-db9e8abd3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rectangles[]\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# 加载面部检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 加载预训练的人脸特征检测器\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('mm2.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 使用dlib检测面部\n",
    "faces = detector(gray)\n",
    "print(faces)\n",
    "for face in faces:\n",
    "    # 获取面部的68个关键点\n",
    "    landmarks = predictor(gray, face)\n",
    "    # 提取鼻子的轮廓\n",
    "    nose_points = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(27, 36)]\n",
    "    nose_contour = np.array(nose_points, dtype=np.int32)\n",
    "    # 在图像上绘制鼻子的轮廓\n",
    "    cv2.polylines(img, [nose_contour], True, (0, 255, 0), 2)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Face and Nose Contour Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a894928-9b0a-4370-a70d-5024651ceaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('mm1.jpg')\n",
    "\n",
    "# 使用face_recognition库加载图像中的面部\n",
    "face_locations = face_recognition.face_locations(img)\n",
    "print(face_locations)\n",
    "for face_location in face_locations:\n",
    "    # 获取面部区域的坐标\n",
    "    top, right, bottom, left = face_location\n",
    "\n",
    "    # 提取面部区域\n",
    "    face_image = img[top:bottom, left:right]\n",
    "\n",
    "    # 使用face_recognition库查找鼻子的关键点\n",
    "    face_landmarks = face_recognition.face_landmarks(face_image)\n",
    "    for landmarks in face_landmarks:\n",
    "        nose_points = landmarks['nose_bridge'] + landmarks['nose_tip']\n",
    "        nose_contour = np.array(nose_points, dtype=np.int32)\n",
    "        # 在图像上绘制鼻子的轮廓\n",
    "        cv2.polylines(img, [nose_contour], True, (0, 255, 0), 2)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Face and Nose Contour Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2958c10-a7b5-44bb-ba90-2a7f9b430e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('mm1.jpg')\n",
    "\n",
    "# 将图像转换为灰度\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 显示灰度图像\n",
    "cv2.imshow('Gray Image', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd9f8a-6220-4809-8c27-8f9c7586c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('tttt1.png')\n",
    "\n",
    "# 将图像转换为灰度\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 计算像素点总数\n",
    "total_pixels = gray.shape[0] * gray.shape[1]\n",
    "\n",
    "# 计算要标记的像素点数量（5%）\n",
    "num_pixels_to_mark = int(0.05 * total_pixels)\n",
    "\n",
    "# 找到灰度图像中最高的像素点坐标\n",
    "top_pixels_indices = np.unravel_index(np.argsort(-gray, axis=None)[:num_pixels_to_mark], gray.shape)\n",
    "\n",
    "# 在原始图像上标记这些像素点\n",
    "for i in range(len(top_pixels_indices[0])):\n",
    "    cv2.circle(img, (top_pixels_indices[1][i], top_pixels_indices[0][i]), 3, (0, 255, 0), -1)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Top 5% Pixels', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b4f27-651f-4c0d-8188-79b18f1735d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('tttt1.png')\n",
    "\n",
    "# 将图像转换为灰度\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 计算像素点总数\n",
    "total_pixels = gray.shape[0] * gray.shape[1]\n",
    "\n",
    "# 计算要标记的像素点数量（5%）\n",
    "num_pixels_to_mark = int(0.05 * total_pixels)\n",
    "\n",
    "# 找到灰度图像中最高的像素点坐标\n",
    "top_pixels_indices = np.unravel_index(np.argsort(-gray, axis=None)[:num_pixels_to_mark], gray.shape)\n",
    "\n",
    "# 计算标记像素点的中心坐标\n",
    "center_y = int(np.mean(top_pixels_indices[0]))\n",
    "center_x = int(np.mean(top_pixels_indices[1]))\n",
    "\n",
    "# 在原始图像上绘制鼻子\n",
    "cv2.circle(img, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Nose Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21018e67-f6e4-4153-911b-23967c38b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('tttt1.png')\n",
    "\n",
    "# 将图像转换为灰度\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 计算像素点总数\n",
    "total_pixels = gray.shape[0] * gray.shape[1]\n",
    "\n",
    "# 计算要标记的像素点数量（5%）\n",
    "num_pixels_to_mark = int(0.05 * total_pixels)\n",
    "\n",
    "# 找到灰度图像中最高的像素点坐标\n",
    "top_pixels_indices = np.unravel_index(np.argsort(-gray, axis=None)[:num_pixels_to_mark], gray.shape)\n",
    "\n",
    "# 获取标记像素点所在的矩形区域\n",
    "top_left_y = min(top_pixels_indices[0])\n",
    "top_left_x = min(top_pixels_indices[1])\n",
    "bottom_right_y = max(top_pixels_indices[0])\n",
    "bottom_right_x = max(top_pixels_indices[1])\n",
    "\n",
    "# 在原始图像上绘制边界框\n",
    "cv2.rectangle(img, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), (0, 255, 0), 2)\n",
    "\n",
    "# 显示结果\n",
    "cv2.imshow('Nose Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529c989e-6f4d-44c8-a9b0-4b0538ec3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 加载预训练的DeepLabV3模型\n",
    "model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 图像预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 读取并预处理待分割的图像\n",
    "image = Image.open('tt2.jpg')\n",
    "input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)['out'][0]\n",
    "    output_predictions = output.argmax(0)\n",
    "\n",
    "# 提取鼻子区域的像素\n",
    "nose_pixels = torch.where(output_predictions == 1)\n",
    "\n",
    "# 创建一个与原始图像相同大小的空白图像\n",
    "segmented_image = torch.zeros_like(input_tensor)\n",
    "\n",
    "# 将鼻子区域的像素复制到空白图像中\n",
    "segmented_image[:, nose_pixels[0], nose_pixels[1]] = input_tensor[:, nose_pixels[0], nose_pixels[1]]\n",
    "\n",
    "# 保存分割后的图像\n",
    "output_image = transforms.ToPILImage()(segmented_image.squeeze(0))\n",
    "output_image.save('segmented_nose.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b39e0c-4cb3-4ee5-8b5b-b4a3fba8f2e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 167 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m segmented_image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(input_tensor)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 将人像区域的像素复制到空白图像中\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m segmented_image[:, person_pixels[\u001b[38;5;241m0\u001b[39m], person_pixels[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43minput_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_pixels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_pixels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 将输出像素值缩放到0-255范围\u001b[39;00m\n\u001b[1;32m     36\u001b[0m segmented_image \u001b[38;5;241m=\u001b[39m segmented_image \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 167 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 加载预训练的DeepLabV3模型\n",
    "model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 图像预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 读取并预处理待分割的图像\n",
    "image = Image.open('tt2.jpg')\n",
    "input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)['out'][0]\n",
    "    output_predictions = output.argmax(0)\n",
    "\n",
    "# 提取人像区域的像素\n",
    "person_pixels = torch.where(output_predictions == 15)  # 在COCO数据集中，人像类别为15\n",
    "\n",
    "# 创建一个与原始图像相同大小的空白图像\n",
    "segmented_image = torch.zeros_like(input_tensor)\n",
    "\n",
    "# 将人像区域的像素复制到空白图像中\n",
    "segmented_image[:, person_pixels[0], person_pixels[1]] = input_tensor[:, person_pixels[0], person_pixels[1]]\n",
    "\n",
    "# 将输出像素值缩放到0-255范围\n",
    "segmented_image = segmented_image * 255\n",
    "segmented_image = segmented_image.clamp(0, 255)\n",
    "\n",
    "# 转换为uint8类型\n",
    "segmented_image = segmented_image.byte()\n",
    "\n",
    "# 保存分割后的图像\n",
    "output_image = transforms.ToPILImage()(segmented_image.squeeze(0))\n",
    "output_image.save('segmented_person.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd51a5ae-50d8-469f-8400-5a22d2552852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "# 加载预训练的 DeepLabv3 模型\n",
    "model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 图像预处理\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(image).unsqueeze(0)\n",
    "\n",
    "# 加载图像\n",
    "image_path = \"tt1.jpg\"\n",
    "input_image = preprocess_image(image_path)\n",
    "\n",
    "# 推理\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)['out'][0]\n",
    "output_predictions = output.argmax(0)\n",
    "\n",
    "# 将预测结果保存为图像\n",
    "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "output_predictions_rgb = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(image.size)\n",
    "output_predictions_rgb.putpalette(colors)\n",
    "output_predictions_rgb.save(\"output_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321a7d2d-66b2-46db-bd3c-1d1370ebb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 加载预训练的 DeepLabv3 模型\n",
    "model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 图像预处理\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(image).unsqueeze(0)\n",
    "\n",
    "# 加载图像\n",
    "image_path = \"tt2.jpg\"\n",
    "input_image = preprocess_image(image_path)\n",
    "\n",
    "# 推理\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)['out'][0]\n",
    "output_predictions = output.argmax(0).byte().cpu().numpy()\n",
    "\n",
    "# 将预测结果转换为面部区域标签\n",
    "# 这里假设输出的类别为：0-背景，1-眼睛，2-鼻子，3-嘴巴，以此类推\n",
    "# 可根据实际情况修改对应的标签值\n",
    "face_regions = {\n",
    "    0: [0, 0, 0],  # 背景\n",
    "    1: [255, 0, 0],  # 眼睛（红色）\n",
    "    2: [0, 255, 0],  # 鼻子（绿色）\n",
    "    3: [0, 0, 255]   # 嘴巴（蓝色）\n",
    "    # 添加更多的面部区域标签和对应的颜色\n",
    "}\n",
    "\n",
    "# 创建一个空白图像，将面部区域填充上颜色\n",
    "output_image = np.zeros((output_predictions.shape[0], output_predictions.shape[1], 3), dtype=np.uint8)\n",
    "for label, color in face_regions.items():\n",
    "    output_image[output_predictions == label] = color\n",
    "\n",
    "# 将结果保存为图像\n",
    "output_image = Image.fromarray(output_image)\n",
    "output_image.save(\"output_face_segmentation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7bcd8-855b-475d-afe5-1bfd59f9ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "输出后的图片为黑色怎么办"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
